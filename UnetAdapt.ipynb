{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOX78yFa345Yon4PkJqqyU1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Salva13s/HybridModel/blob/main/UnetAdapt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKKFqTg6U-wA",
        "outputId": "96fe4697-7195-474f-e39a-69e6b2d015de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler"
      ],
      "metadata": {
        "id": "52qPwS_3U7E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_dir, density_map_dir, pseudo_map_dir=None, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.density_map_dir = density_map_dir\n",
        "        self.pseudo_map_dir = pseudo_map_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        self.density_map_files = sorted([f for f in os.listdir(density_map_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "        if pseudo_map_dir:\n",
        "            self.pseudo_map_files = sorted([f for f in os.listdir(pseudo_map_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        else:\n",
        "            self.pseudo_map_files = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        density_map_path = os.path.join(self.density_map_dir, self.density_map_files[idx])\n",
        "\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        density_map = Image.open(density_map_path).convert('L')\n",
        "\n",
        "        if self.pseudo_map_dir:\n",
        "            pseudo_map_path = os.path.join(self.pseudo_map_dir, self.pseudo_map_files[idx])\n",
        "            pseudo_map = Image.open(pseudo_map_path).convert('L')\n",
        "        else:\n",
        "            pseudo_map = None\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            density_map = self.transform(density_map)\n",
        "            if pseudo_map:\n",
        "                pseudo_map = self.transform(pseudo_map)\n",
        "\n",
        "        # Devolver también el nombre del archivo de imagen\n",
        "        return image, density_map, pseudo_map, self.image_files[idx]"
      ],
      "metadata": {
        "id": "ou00Sxz5VO-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "vKQj2ZFsVUFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_dir = '/content/drive/MyDrive/1 Tesis/Fish/DataDividido/train/reales_resized'\n",
        "train_density_map_dir = '/content/drive/MyDrive/1 Tesis/Fish/DataDividido/train/generadas_resized'\n",
        "train_pseudo_map_dir = '/content/drive/MyDrive/1 Tesis/Fish/DataDividido/train/PsMapas'\n",
        "\n",
        "val_image_dir = '/content/drive/MyDrive/1 Tesis/Fish/DataDividido/val/reales_resized'\n",
        "val_density_map_dir = '/content/drive/MyDrive/1 Tesis/Fish/DataDividido/val/generadas_resized'\n",
        "val_pseudo_map_dir = '/content/drive/MyDrive/1 Tesis/Fish/DataDividido/val/PsMapas'\n",
        "\n",
        "test_image_dir = '/content/drive/MyDrive/1 Tesis/Fish/DataDividido/test/reales'\n",
        "test_density_map_dir = '/content/drive/MyDrive/1 Tesis/Fish/DataDividido/test/generadas_resized'\n",
        "test_pseudo_map_dir = '/content/drive/MyDrive/1 Tesis/Fish/DataDividido/test/PsMapas'\n",
        "\n",
        "train_dataset = CustomDataset(train_image_dir, train_density_map_dir, train_pseudo_map_dir, transform=transform)\n",
        "val_dataset = CustomDataset(val_image_dir, val_density_map_dir, val_pseudo_map_dir, transform=transform)\n",
        "test_dataset = CustomDataset(test_image_dir, test_density_map_dir, test_pseudo_map_dir, transform=transform)"
      ],
      "metadata": {
        "id": "GCgbB75QVY7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=6, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=6, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=6, shuffle=False)"
      ],
      "metadata": {
        "id": "V1QevzaJWMw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        def conv_block(in_channels, out_channels):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        def upconv_block(in_channels, out_channels):\n",
        "            return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "\n",
        "        self.encoder1 = conv_block(in_channels, 64)\n",
        "        self.encoder2 = conv_block(64, 128)\n",
        "        self.encoder3 = conv_block(128, 256)\n",
        "        self.encoder4 = conv_block(256, 512)\n",
        "        self.encoder5 = conv_block(512, 1024)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.upconv4 = upconv_block(1024, 512)\n",
        "        self.decoder4 = conv_block(1024, 512)\n",
        "        self.upconv3 = upconv_block(512, 256)\n",
        "        self.decoder3 = conv_block(512, 256)\n",
        "        self.upconv2 = upconv_block(256, 128)\n",
        "        self.decoder2 = conv_block(256, 128)\n",
        "        self.upconv1 = upconv_block(128, 64)\n",
        "        self.decoder1 = conv_block(128, 64)\n",
        "\n",
        "        self.conv_final = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc2 = self.encoder2(self.pool(enc1))\n",
        "        enc3 = self.encoder3(self.pool(enc2))\n",
        "        enc4 = self.encoder4(self.pool(enc3))\n",
        "        enc5 = self.encoder5(self.pool(enc4))\n",
        "\n",
        "        dec4 = self.upconv4(enc5)\n",
        "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
        "        dec4 = self.decoder4(dec4)\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
        "        dec3 = self.decoder3(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
        "        dec1 = self.decoder1(dec1)\n",
        "\n",
        "        return self.conv_final(dec1)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_unet = UNet().to(device)"
      ],
      "metadata": {
        "id": "0J9rVguxWQbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaptiveNet(nn.Module):\n",
        "    def __init__(self, unet_output_channels=1):\n",
        "        super(AdaptiveNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(unet_output_channels + 1, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 1, kernel_size=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, unet_output, pseudo_density_map):\n",
        "        x = torch.cat((unet_output, pseudo_density_map), dim=1)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.conv2(x)\n",
        "        return x\n",
        "\n",
        "model_adaptive = AdaptiveNet().to(device)"
      ],
      "metadata": {
        "id": "44XCnHEVWVZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_jointly(unet_model, adaptive_model, train_loader, val_loader, num_epochs=50):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(list(unet_model.parameters()) + list(adaptive_model.parameters()), lr=1e-4)\n",
        "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
        "\n",
        "    unet_model.to(device)\n",
        "    adaptive_model.to(device)\n",
        "\n",
        "    train_loss_history = []\n",
        "    val_loss_history = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        unet_model.train()\n",
        "        adaptive_model.train()\n",
        "\n",
        "        running_loss = 0.0\n",
        "\n",
        "        # Entrenamiento\n",
        "        for (images, density_maps, pseudo_maps, _) in train_loader:\n",
        "            images, density_maps = images.to(device), density_maps.to(device)\n",
        "            pseudo_maps = pseudo_maps.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            unet_output = unet_model(images)\n",
        "            adaptive_output = adaptive_model(unet_output, pseudo_maps)\n",
        "\n",
        "            loss = criterion(adaptive_output, density_maps)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        epoch_loss_train = running_loss / len(train_loader.dataset)\n",
        "        train_loss_history.append(epoch_loss_train)\n",
        "\n",
        "        # Pérdida de validación\n",
        "        unet_model.eval()\n",
        "        adaptive_model.eval()\n",
        "        running_loss_val = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for (images, density_maps, pseudo_maps, _) in val_loader:\n",
        "                images, density_maps = images.to(device), density_maps.to(device)\n",
        "                pseudo_maps = pseudo_maps.to(device)\n",
        "\n",
        "                unet_output = unet_model(images)\n",
        "                adaptive_output = adaptive_model(unet_output, pseudo_maps)\n",
        "\n",
        "                loss = criterion(adaptive_output, density_maps)\n",
        "                running_loss_val += loss.item() * images.size(0)\n",
        "\n",
        "        epoch_loss_val = running_loss_val / len(val_loader.dataset)\n",
        "        val_loss_history.append(epoch_loss_val)\n",
        "\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}, Train Loss: {epoch_loss_train:.4f}, Validation Loss: {epoch_loss_val:.4f}')\n",
        "        scheduler.step(epoch_loss_val)\n",
        "    return train_loss_history, val_loss_history"
      ],
      "metadata": {
        "id": "d56dzRPnWbKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_history = train_jointly(model_unet, model_adaptive, train_loader, val_loader, num_epochs=50)"
      ],
      "metadata": {
        "id": "Tt9m9p_rWfIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "def evaluate_and_save_predictions(unet, adaptive_model, test_loader, save_dir):\n",
        "    unet.eval()\n",
        "    adaptive_model.eval()\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Ajusta para ignorar el nombre del archivo\n",
        "        for batch_idx, (inputs, true_density_maps, pseudo_maps, _) in enumerate(test_loader):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            true_density_maps = true_density_maps.to(device)\n",
        "            pseudo_maps = pseudo_maps.to(device)\n",
        "\n",
        "            predicted_density_maps_unet = unet(inputs)\n",
        "            predicted_density_maps_adaptive = adaptive_model(predicted_density_maps_unet, pseudo_maps)\n",
        "\n",
        "            for i in range(len(predicted_density_maps_adaptive)):\n",
        "                pred_map = predicted_density_maps_adaptive[i].cpu().squeeze(0)\n",
        "                # Usa el nombre de archivo original en lugar de 'predicted_map' y un número\n",
        "                original_filename = os.path.splitext(_[i])[0] + \"_predicted.png\"\n",
        "                save_image(pred_map, os.path.join(save_dir, original_filename))\n",
        "\n",
        "    print(f'Predicciones guardadas en {save_dir}')\n",
        "\n",
        "save_directory = '/content/drive/MyDrive/1 Tesis/Fish/UnetAdapt/FishPred50'\n",
        "\n",
        "evaluate_and_save_predictions(model_unet, model_adaptive, test_loader, save_directory)"
      ],
      "metadata": {
        "id": "9my4C8jnhlff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd55a71b-7e88-4f91-e2b3-eade83f5e2d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicciones guardadas en /content/drive/MyDrive/1 Tesis/Fish/UnetAdapt/FishPred50\n"
          ]
        }
      ]
    }
  ]
}